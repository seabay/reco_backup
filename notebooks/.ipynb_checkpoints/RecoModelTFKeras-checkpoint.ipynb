{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import builtins\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "#from keras import backend as K\n",
    "from extra_keras_metrics import average_precision_at_k\n",
    "from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "import pydot as pyd\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#from keras.layers import Input, Dense, Embedding, Lambda, Reshape, Flatten, Average\n",
    "#from keras.models import Model\n",
    "#from keras.backend import mean, max\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "keras.utils.vis_utils.pydot = pyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecoDNN():\n",
    "    \n",
    "    def __init__(self, max_transaction_history = 50, max_product_click_history = 50, max_promotion_click_history = 50,\n",
    "                 category_size = 100, single_categorical_features = None, numeric_features_size = 10,\n",
    "                 hidden_layer1_size = 256, hidden_layer2_size = 128, hidden_layer3_size = 64, activation='relu',\n",
    "                input_embedding_size = 128):\n",
    "        \n",
    "        self.max_transaction_history = max_transaction_history\n",
    "        self.max_product_click_history = max_product_click_history\n",
    "        self.max_promotion_click_history = max_promotion_click_history\n",
    "        self.category_size = category_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.hidden_layer3_size = hidden_layer3_size\n",
    "        self.single_categorical_features = single_categorical_features\n",
    "        self.numeric_features_size = numeric_features_size\n",
    "        self.activation = activation\n",
    "        self.input_embedding_size = input_embedding_size\n",
    "        \n",
    "        self.category_embeddings = tf.keras.layers.Embedding(output_dim=self.input_embedding_size, input_dim = self.category_size, \n",
    "                       input_length = builtins.max(self.max_transaction_history, self.max_product_click_history, self.max_promotion_click_history), mask_zero=True, name='category_embeddings')\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        inp_layer, inp_embed = self.create_input()\n",
    "        \n",
    "        v = tf.keras.layers.Dense(self.hidden_layer1_size, activation = self.activation)(tf.keras.layers.concatenate(inp_embed)) \n",
    "        v = tf.keras.layers.Dense(self.hidden_layer2_size, activation = self.activation)(v)\n",
    "        v = tf.keras.layers.Dense(self.hidden_layer3_size, activation = self.activation, name='user_embedding')(v)\n",
    "        output = tf.keras.layers.Dense(self.category_size, activation ='softmax', name='softmax_layer')(v)\n",
    "        self.model = tf.keras.models.Model(inputs = inp_layer, outputs = [output])    \n",
    "        \n",
    "    \n",
    "    def create_input(self):\n",
    "        \n",
    "        transaction_cols = [x for x in range(self.max_transaction_history)]\n",
    "        product_click_cols = [x for x in range(self.max_product_click_history)]\n",
    "        promotion_click_cols = [x for x in range(self.max_promotion_click_history)]\n",
    "        seq_category_cols = [transaction_cols, product_click_cols, promotion_click_cols]\n",
    "        \n",
    "        seqs = []\n",
    "        for i, grp in enumerate(seq_category_cols):\n",
    "            seqs.append(self.seq_categorical_input('seq_categorical_' + str(i), len(grp)))\n",
    "\n",
    "        singles = []\n",
    "        if self.single_categorical_features:\n",
    "            for col in self.single_categorical_features:\n",
    "                singles.append(self.singe_categorical_input(str(col), self.single_categorical_features[col]))\n",
    "\n",
    "        nums = self.continous_inputs(self.numeric_features_size)\n",
    "\n",
    "        inp_layer =  [s[0] for s in seqs]\n",
    "        inp_layer += [s[0] for s in singles]\n",
    "        inp_layer.append(nums[0])\n",
    "        inp_embed = [s[1] for s in seqs]\n",
    "        inp_embed += [s[1] for s in singles]\n",
    "        inp_embed.append(nums[1])\n",
    "               \n",
    "        return inp_layer, inp_embed\n",
    "    \n",
    "    \n",
    "    def seq_categorical_input(self, name, max_history):\n",
    "    \n",
    "        seq = tf.keras.layers.Input(shape=(max_history,), dtype='int32', name=name)\n",
    "        input_embeddings = self.category_embeddings(seq)\n",
    "        #avg = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1), name= name + '_avg_embedding')\n",
    "        #avg_embedding = tf.reduce_mean(input_embeddings, axis=0), name= name + '_avg_embedding'))\n",
    "        avg_embedding = tf.keras.layers.GlobalAveragePooling1D(name=name + '_avg_embedding')(input_embeddings, mask=self.category_embeddings.compute_mask(seq))\n",
    "\n",
    "\n",
    "        #maxf = Lambda(lambda x: max(x, axis=1), name = name + '_max_embedding')\n",
    "        #max_embedding = maxf(input_embeddings)\n",
    "\n",
    "        return seq, avg_embedding   #keras.layers.add([avg_embedding, max_embedding])\n",
    "\n",
    "    \n",
    "    def singe_categorical_input(self, name, unique_size):\n",
    "        single = tf.keras.layers.Input(shape=(1,), dtype='int32', name=name)\n",
    "        embeddings = tf.keras.layers.Embedding(output_dim = self.input_embedding_size, input_dim = unique_size, \n",
    "                           input_length=1, name=name + '_embedding')(single)\n",
    "        embeddings = tf.keras.layers.Flatten(name = 'flatten_' + name)(embeddings)\n",
    "        return single, embeddings\n",
    "    \n",
    "    def continous_inputs(self, size=None, name='numeric'):\n",
    "        inp = tf.keras.layers.Input(shape=(size,), dtype='float32', name=name)\n",
    "        return inp, inp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "max_transaction_history = 50\n",
    "max_product_click_history = 50\n",
    "max_promotion_click_history = 50\n",
    "input_embedding_size = 128\n",
    "category_size = 100\n",
    "numeric_size = 10\n",
    "\n",
    "data1 = np.random.randint(category_size, size=(data_size, max_transaction_history-2))\n",
    "data1 = tf.keras.preprocessing.sequence.pad_sequences(data1, 50, padding='post')\n",
    "data2 = np.random.randint(category_size, size=(data_size, max_product_click_history-3))\n",
    "data2 = tf.keras.preprocessing.sequence.pad_sequences(data2, 50, padding='post')\n",
    "\n",
    "data3 = np.random.randint(category_size, size=(data_size, max_promotion_click_history-4))\n",
    "data3 = tf.keras.preprocessing.sequence.pad_sequences(data3, 50, padding='post')\n",
    "\n",
    "inputs = [data1, data2, data3]\n",
    "\n",
    "single_category_cols = {105:3,106:5,107:10}   ## such as location : unique_value_size\n",
    "for k in single_category_cols:\n",
    "    inputs.append(np.random.randint(single_category_cols[k], size=(data_size, 1)))\n",
    "\n",
    "num1 = np.random.random(size=(data_size, numeric_size))\n",
    "inputs.append(num1)\n",
    "\n",
    "labels = np.random.randint(category_size, size=(data_size, 1))\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=category_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46, 49, 23, ..., 52,  0,  0],\n",
       "       [74,  8, 48, ..., 89,  0,  0],\n",
       "       [44, 26, 52, ..., 43,  0,  0],\n",
       "       ...,\n",
       "       [19, 66,  5, ..., 79,  0,  0],\n",
       "       [78, 46, 52, ..., 77,  0,  0],\n",
       "       [33, 66, 71, ..., 65,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs1 = inputs.copy()\n",
    "#inputs1.append(labels)\n",
    "#merge = np.hstack(inputs1)\n",
    "#np.savetxt('../data/features.csv', merge, fmt=\"%2.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test tfrecord inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save tfrecord file for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_filename = \"../data/tf.tfrecord\"\n",
    "\n",
    "def float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=list(value)))\n",
    "\n",
    "with tf.python_io.TFRecordWriter(output_filename) as writer:\n",
    "    for (v1,v2,v3,v4,v5,v6,v7,v8) in zip(data1, data2, data3, inputs[3], inputs[4], inputs[5], inputs[6], labels):\n",
    "        features = {'seq_categorical_0': int64_feature(v1), 'seq_categorical_1': int64_feature(v2),\n",
    "                    'seq_categorical_2': int64_feature(v3),'105': int64_feature(v4),\n",
    "                    '106': int64_feature(v5),'107': int64_feature(v6), 'numeric': float_feature(v7),\n",
    "                    'labels': float_feature(v8)}\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tfrecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(example_proto):\n",
    "    features = {\"seq_categorical_0\":tf.FixedLenFeature([50],tf.int64),\n",
    "                \"seq_categorical_1\":tf.FixedLenFeature([50], tf.int64),\n",
    "                \"seq_categorical_2\":tf.FixedLenFeature([50], tf.int64),\n",
    "                \"105\":tf.FixedLenFeature([1], tf.int64),\n",
    "                \"106\":tf.FixedLenFeature([1], tf.int64),\n",
    "                \"107\":tf.FixedLenFeature([1], tf.int64),\n",
    "                \"numeric\":tf.FixedLenFeature([10], tf.float32),\n",
    "                \"labels\":tf.FixedLenFeature([1], tf.float32),\n",
    "         }\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    #return parsed_features\n",
    "    return (parsed_features[\"seq_categorical_0\"], parsed_features[\"seq_categorical_1\"], parsed_features[\"seq_categorical_2\"], parsed_features[\"105\"], parsed_features[\"106\"], parsed_features[\"107\"], parsed_features[\"numeric\"]), parsed_features[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-3b66a34d5f3d>:3: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "#debug generated tfrecord\n",
    "try:\n",
    "    for i, str_rec in enumerate(tf.python_io.tf_record_iterator(\"../data/tf.tfrecord\")):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(str_rec)\n",
    "        #print(i, dict(example.features.feature).keys())\n",
    "except:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3=tf.data.TFRecordDataset('../data/tf.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3=ds3.map(parse_function, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = ds3.repeat()  # Repeat the input indefinitely.\n",
    "ds3 = ds3.batch(32)\n",
    "#iterator = ds3.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorShape([Dimension(None), Dimension(50)]),\n",
       "  TensorShape([Dimension(None), Dimension(50)]),\n",
       "  TensorShape([Dimension(None), Dimension(50)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(10)])),\n",
       " TensorShape([Dimension(None), Dimension(1)]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds3.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dataset from ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2=tf.data.Dataset.from_tensor_slices(\n",
    "    ({'seq_categorical_0': data1, 'seq_categorical_1': data2, 'seq_categorical_2': data3, \n",
    "     '105': inputs[3], '106': inputs[4],'107': inputs[5],'numeric': inputs[6]},\n",
    "     {'softmax_layer': one_hot_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2=ds2.repeat()\n",
    "ds2=ds2.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds2.shuffle(buffer_size=1024).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = tf.data.Dataset.from_tensor_slices((data1, data2, data3, inputs[3], inputs[4], inputs[5], num1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(50)]),\n",
       " TensorShape([Dimension(50)]),\n",
       " TensorShape([Dimension(50)]),\n",
       " TensorShape([Dimension(1)]),\n",
       " TensorShape([Dimension(1)]),\n",
       " TensorShape([Dimension(1)]),\n",
       " TensorShape([Dimension(10)]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = tf.data.Dataset.from_tensor_slices((labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = input_dataset.batch(32).repeat()\n",
    "output_dataset = output_dataset.batch(32).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.zip((input_dataset, output_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorShape([Dimension(None), Dimension(50)]),\n",
       "  TensorShape([Dimension(None), Dimension(50)]),\n",
       "  TensorShape([Dimension(None), Dimension(50)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(1)]),\n",
       "  TensorShape([Dimension(None), Dimension(10)])),\n",
       " TensorShape([Dimension(None), Dimension(1)]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecoDNN(max_transaction_history,max_product_click_history, max_promotion_click_history, category_size,\n",
    "                numeric_features_size = numeric_size, input_embedding_size = input_embedding_size,\n",
    "                single_categorical_features = single_category_cols).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='../figures/model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time model.fit(x=inputs, y=labels, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.fit(ds3, epochs=50, steps_per_epoch=int(10000//32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=data_generator.data_generator('../data/features.csv', 64, [50, 100, 150], [150,151,152], [153])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator=data_generator.DataGenerator('../data/features.csv', 10000, 64, 100, [50, 100, 150], [150,151,152], [153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.fit_generator(generator,steps_per_epoch=10000//64, verbose=1, epochs=50, shuffle=True, use_multiprocessing=True, workers=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
